# ğŸ§  Posture Analysis Job Offloading System (GPU-Based with Prometheus)

This project receives posture images from Raspberry Pis and offloads posture analysis jobs to the most underloaded GPU-equipped worker node in a Kubernetes cluster. The system relies on Prometheus to monitor GPU usage and dynamically patches and deploys Kubernetes jobs to the optimal node.

---

## ğŸ“¦ Project Features

- ğŸ“¸ Posture image input via MQTT
- ğŸ“Š GPU load-based job scheduling using Prometheus
- ğŸ³ Dockerized posture analyzer with Supabase DB logging
- â˜ï¸ Jobs offloaded via Kubernetes and node affinity
- ğŸš« Master node tainted to avoid overload
- ğŸ§½ Automatic job cleanup after completion

---

## ğŸ“ Folder Structure

```
Master Tainted + GPU Based Scheduling/
â”œâ”€â”€ build_and_push.py           # Builds and pushes Docker image, taints master node
â”œâ”€â”€ stop.py                    # Stops system and untaints master
â”œâ”€â”€ cpu_monitor_and_offload.py # Prometheus-based job scheduler
â”œâ”€â”€ mqtt_posture_analyzer_with_db.py # Image processing entrypoint
â”œâ”€â”€ gpu_scaler.py              # Manual Prometheus GPU stats tester
â”œâ”€â”€ Dockerfile                 # Posture analyzer image definition
â”œâ”€â”€ docker-compose.yml         # Local run support
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ posture-job.yaml           # Template for K8s job (patched dynamically)
â”œâ”€â”€ patched-job.yaml           # Final job applied to cluster
```

---

## ğŸš€ How to Run the Project

### âœ… Prerequisites

- Kubernetes cluster with labeled worker nodes (`role=worker`)
- Prometheus scraping GPU usage metrics (`jetson_gpu_usage_percent`, etc.)
- Docker + Docker Hub credentials
- Supabase PostgreSQL setup
- Python 3.8+ environment

### ğŸ”¨ 1. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ§± 2. Build and Launch the System

```bash
python3 build_and_push.py
```

This will:
- Stop previous containers/images
- Build & push Docker image (`shahroz90/posture-analyzer`)
- Taint master node
- Start monitoring + auto-offloading jobs

### ğŸ§¹ 3. Stop the System

```bash
python3 stop.py
```

This will:
- Kill offloading monitor
- Delete Kubernetes jobs
- Bring down containers
- Untaint the master node

---

## âš™ï¸ How Offloading Works

- GPU usage is queried from Prometheus (localhost:9090)
- If any worker node has GPU usage < 60%, it is selected
- `posture-job.yaml` is patched with:
  ```yaml
  nodeName: <selected-node>
  ```
- Job is launched via:
  ```bash
  kubectl apply -f patched-job.yaml
  ```

Each job runs:
- `mqtt_posture_analyzer_with_db.py` inside the container
- Subscribes to MQTT broker, processes images, logs results to Supabase

---

## ğŸ“‚ Key Scripts

### `build_and_push.py`
- Builds & pushes image
- Taints master node
- Starts monitor and listener

### `stop.py`
- Deletes jobs and containers
- Kills `cpu_monitor_and_offload.py`
- Untaints master node

### `cpu_monitor_and_offload.py`
- Prometheus-based scheduler
- Patches and deploys job to best node

### `gpu_scaler.py`
- For testing Prometheus GPU queries manually

---

## ğŸ”Œ MQTT + Supabase

The analyzer script:
- Subscribes to topics like `images/pi1`, `images/pi2`
- Runs posture detection using MediaPipe
- Logs:
  - pi_id, filename, angles, posture status, timestamps
- Saves to: Supabase PostgreSQL

---

## ğŸ›  Prometheus Metrics Used

- `jetson_gpu_usage_percent` (for Jetson AGX nodes)
- `jetson_orin_gpu_load_percent` (for Jetson Orin nodes)

---

## ğŸ“ Notes

- `ttlSecondsAfterFinished: 60` in job spec cleans up jobs automatically
- Taint on master ensures workloads go to GPU workers
- You must rebuild and push image after changing `mqtt_posture_analyzer_with_db.py`

---

## ğŸ“Š Future Improvements

- ğŸ”„ Integrate KEDA external scaler (gRPC Prometheus scaler)
- ğŸ“ˆ Add Grafana dashboards
- ğŸ§  Real-time DB feedback loop for posture analytics
- ğŸ§  Combine with memory/CPU-based scalers

---

## ğŸ‘¤ Author

**Muhammad Shahroz Abbas**  
ğŸ“§ [shahroz.abbas@oulu.fi](mailto:shahroz.abbas@oulu.fi)  


---

âœ… Ready for testing and deployment.
