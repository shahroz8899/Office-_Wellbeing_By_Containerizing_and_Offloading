
---

### **1. KEDA Scraping Loop (Every 30 Seconds)**

* **KEDA polls Prometheus every 30 seconds**

  * It gathers the **GPU usage of all nodes**.
  * It calculates the **average GPU usage per node**.

---

### **2. KEDA IsActive() Logic**

* If **any node is under the GPU threshold** (e.g., 60%), KEDA returns `Active = True`.
* If **all nodes are overloaded**, KEDA returns `Active = False` — nothing runs.

once KEDA reports **Active = true**:

1. **First-time scheduling (initial placement)**

* Spread new pods **evenly** across all available nodes.
* If the count isn’t divisible evenly, place the “extra” pod(s) on the node with the **lowest GPU usage**; if there’s a tie, **pick randomly**.
  *(This “even spread + lowest-usage remainder with random tie-break” is an explicit new rule you want added for the initial placement.)*

2. **Every loop (\~30s): re-check & gently rebalance**

* KEDA calls `IsActive()` roughly every **30s** (your ScaledJob sets `pollingInterval: 30` and uses the external scaler address), so each loop re-evaluates the cluster. &#x20;
* The scaler/script will re-pull **30s average GPU usage** per node from Prometheus and decide activity/reshuffles based on those averages. (You’ve standardized on a 30s window via `GPU_AVG_WINDOW`, and `IsActive` uses 30s-avg reads before invoking the offload pass.)  &#x20;
* If still **Active = true**, look for **overloaded** nodes (≥ offload threshold) and **offload at most one pod per overloaded node per loop** — slow and steady to prevent thrashing. (Your offloader explicitly moves only one pod per overloaded node each pass.) &#x20;
* Pick a destination node that is **under the threshold** and has the **lowest GPU usage**; if multiple nodes tie at that minimum, **choose randomly** to avoid dog-piling. (Your code already picks the least-busy node; you’ve used random tie-breaks elsewhere, and we’ll keep/apply that tie-break here too.) &#x20;
* To enact the move: patch the Job/ScaledJob with **nodeAffinity** for the chosen node, then **delete exactly that one pod** so it reschedules onto the target node under the updated affinity. Repeat next loop.  &#x20;

3. **Thresholds & decision points**

* You’re separating thresholds: one for KEDA’s “readiness” (should we allow scheduling at all?) and a lower one for **offloading** decisions. Both are applied to **30s averages**.&#x20;

